{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a524a03",
   "metadata": {},
   "source": [
    "## Previous Lesson Review: Day 8 Pandas_Intro\n",
    "\n",
    "In the previous lesson you learned how to:\n",
    "\n",
    "1. Create a dataframe from scratch\n",
    "2. Read in tabular data into a dataframe\n",
    "3. View and access data in the dataframe\n",
    "4. Save and export a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d0f6b",
   "metadata": {},
   "source": [
    "# Day 9: Pandas_Modifications\n",
    "In the previous lesson we learned about dataframes, in this lesson we will learn how to modify dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef752c0",
   "metadata": {},
   "source": [
    "# Goals:\n",
    "\n",
    "Students will be able to :\n",
    "\n",
    "1. Modify dataframe\n",
    "2. Modify values\n",
    "3. Clean data and make a function to import data\n",
    "4. Merge, concat, append\n",
    "5. Automation \n",
    "\n",
    "Here is a picture of panda not letting go of the zookeeper. Sometimes trying to get your data in the format you want feels like you are battling a panda."
   ]
  },
  {
   "attachments": {
    "pd_test.jpeg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4b455167",
   "metadata": {},
   "source": [
    "![pd_test.jpeg](attachment:pd_test.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23f838",
   "metadata": {},
   "source": [
    "# System version when preparing this notebook\n",
    "- python 3.8.11\n",
    "- padas 1.1.3\n",
    "- numpy 1.20.3\n",
    "\n",
    "This lesson was prepared by Maria D Hernandez Limon for NRT Environmental Science Bootcamps 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757fe85",
   "metadata": {},
   "source": [
    "# Set-Up working Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check my versions\n",
    "print (pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the specific directory where the data we want to use is stored\n",
    "datadirectory = '../data/'\n",
    "\n",
    "#this is the directory where we want to store the data we finish analyzing\n",
    "data_out_directory='../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f3d8",
   "metadata": {},
   "source": [
    "# 8. Modifying dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33d4ca",
   "metadata": {},
   "source": [
    "First let's open or pokemon dataset. We will be working with this data for the rest of section 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df=pd.read_csv(datadirectory+'pokemon.csv')\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06299696",
   "metadata": {},
   "source": [
    "### 8.1 Adding new columns\n",
    "Same logic as when we created new dataframes in section 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a723091",
   "metadata": {},
   "source": [
    "- ###  Initialize a new column with some value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start a new series with values from 0 to the size of this table (we get this value from shape)\n",
    "pokemon_df['Test']=np.arange(0,pokemon_df.shape[0])\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb704a2",
   "metadata": {},
   "source": [
    "- ###  Use conditions to create values for your new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5113770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use where from numpy to get conditional values in our new row\n",
    "pokemon_df['Boss']=np.where(pokemon_df['Attack']>150,'strong','weak')\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654942a",
   "metadata": {},
   "source": [
    "- ###  with DICTIONARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary and then use the map function to retrieve values from the dictionary\n",
    "type_color={'Grass':'Green','Fire':'Red','Rock':'Brown','Water':'Blue'}\n",
    "pokemon_df['colors']=pokemon_df['Type 1'].map(type_color)\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b19b8b",
   "metadata": {},
   "source": [
    "- ###  Add Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ce133",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df['Strength']=pokemon_df['Attack']*pokemon_df['Speed']\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf460e69",
   "metadata": {},
   "source": [
    "- ###  Add String columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df['full_type']=pokemon_df['Type 1']+'_'+pokemon_df['Type 2']\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23464a",
   "metadata": {},
   "source": [
    "### 8.2 [removing columns/rows](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120d1a1",
   "metadata": {},
   "source": [
    "- ###  columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we specify axis=1 to drop columns, if we want this change in the original table we use inplace=True\n",
    "pokemon_drop=pokemon_df.drop(columns=['Test','Boss','full_type'], axis=1)\n",
    "pokemon_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c810b",
   "metadata": {},
   "source": [
    "- ###  rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we specify axis=0 to drop rows, if we want this change in the original table we use inplace=True\n",
    "pokemon_drop_row=pokemon_df.drop(labels=[0,2,4],axis=0)\n",
    "pokemon_drop_row.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b31840",
   "metadata": {},
   "source": [
    "### 8.3 remove duplicates\n",
    "\n",
    "We can remove duplicates in our data by selecting a column and which values we want to drop.\n",
    "\n",
    "[DataFrame.drop_duplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)(subset=None, keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_sans_duplicates=pokemon_df.drop_duplicates(subset=['Type 1'],keep='first')\n",
    "# or inplace=True if you want to make the changes to your main table \n",
    "pokemon_sans_duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733638d0",
   "metadata": {},
   "source": [
    "### 8.4 rename columns/index\n",
    "\n",
    "We can rename the labels of the column and the index.\n",
    "\n",
    "DataFrame.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')\n",
    "\n",
    "[RENAME](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e7f18",
   "metadata": {},
   "source": [
    "- ### columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903adf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#within columns pass a dictionary from old to new name\n",
    "pokemon_df.rename(columns={'Total':'Total_Stats'},inplace=True)\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8db778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary outside\n",
    "new_names={'HP':'Hit_Points','Defense':'Def.'}\n",
    "#pass the dictionary to columns\n",
    "pokemon_df.rename(columns=new_names,inplace=True)\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc919f",
   "metadata": {},
   "source": [
    "Pass a list of equal length to pokemon_df.columns to replace all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will import the alphabet\n",
    "import string\n",
    "alphabet=list(string.ascii_uppercase)\n",
    "\n",
    "#creat a list that is the same length as pokemon_df\n",
    "new_names=alphabet[:len(pokemon_df.columns)]\n",
    "\n",
    "pokemon_df.columns=new_names\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b67fab",
   "metadata": {},
   "source": [
    "- ### rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b64094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary inside \n",
    "pokemon_df.rename(index={0:1000,1:2000},inplace=True)\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2196a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary outside\n",
    "new_row_names={1000:0,2000:1}\n",
    "#pass the dictionary to columns\n",
    "pokemon_df.rename(index=new_row_names,inplace=True)\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373493dd",
   "metadata": {},
   "source": [
    "# 8. Skills Practice\n",
    "Create new column named power. I'll define Power as the sum of Attack and Speed. Then create a new table that has all the rows but only 3 columns(Name, Type 1, and Power). Then I want you to change the Type 1 name to Type (without the 1). Sort the Pokemon by Power and only keep the top 5 (strongest). Do this all with one line of code by attaching commands together.\n",
    "\n",
    "First let's read in the dataset again since we made a lot of changes inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df=pd.read_csv(datadirectory+'pokemon.csv')\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first add new column called power to pokemon_df\n",
    "\n",
    "pokemon_df['Power']='?'\n",
    "\n",
    "####all of this can be done with one line of code#####\n",
    "#create new frame with only columns wanted - use loc or iloc to select Name, Type 1, Power\n",
    "#rename the column Type 1 to Type - do you need inplace to be true?\n",
    "#sort_values by power (you want ascending to be True)\n",
    "#keep only the top 5 - iloc is your friend\n",
    "\n",
    "new_subset='?'\n",
    "\n",
    "#show your table                                                                                                            ascending=False).iloc[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4fc22b",
   "metadata": {},
   "source": [
    "# 9. Modify Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046768ec",
   "metadata": {},
   "source": [
    "- ###  9.1 [fillna with values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the colum you want then call .fillna\n",
    "pokemon_df['Type 2'].fillna(value='no type',inplace=True)\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48539479",
   "metadata": {},
   "source": [
    "- ### 9.2 dropna values\n",
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "[dropna documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read table in again because we've done a lot of modifications\n",
    "pokemon_df=pd.read_csv(datadirectory+'pokemon.csv')\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want the changes in your existing table then use inplace=True instead of initializing a new variable\n",
    "#notice here we no longer have pokemon 4 charmander which does not have a type 2\n",
    "drop_null_df=pokemon_df.dropna(subset=['Type 2'])\n",
    "drop_null_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678002c3",
   "metadata": {},
   "source": [
    "- ### 9.3 [replace values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadac621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace needs the old value and new value\n",
    "pokemon_df['Type 2']=pokemon_df['Type 2'].replace('no_type', 'empty')\n",
    "pokemon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ba7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can select a specific set of values and change them something else\n",
    "pokemon_df.loc[pokemon_df['Type 2']=='Poison','Type 2']='Venom'\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select based on position and replace with another value\n",
    "pokemon_df.iloc[0,3]='FIRE'\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97c679",
   "metadata": {},
   "source": [
    "- ###  9.4 Modify Strings\n",
    "I am only showing you basic examples to introduce you to the options. [More resources](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)\n",
    "\n",
    "All the string operations you learned on Day 2 on how to modify strings can be used on columns of dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all mega pokemon\n",
    "#the list comprehension here is a for loop in one line, this comman will iterate through every value in the pokemon_df['Name']\n",
    "#and so the action states at the start, in this case replace 'Mega' with'M*\n",
    "pokemon_df['clean_Mega']=[i.replace('Mega',' M*') for i in pokemon_df['Name']]\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ed072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the string i will become upper case\n",
    "pokemon_df['Name']=[i.upper() for i in pokemon_df['Name']]\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240cd9e",
   "metadata": {},
   "source": [
    "# 9. Skill Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data again because we changed a lot of stuff \n",
    "pokemon_df=pd.read_csv(datadirectory+'pokemon.csv')\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0600999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the clean pokemon data, select all the 'Fire' of Type 1 and make them into 'FIRE' - use loc\n",
    "pokemon_df.loc[?]='FIRE'\n",
    "\n",
    "#after, select the first 10 pokemon and change their Total to 0\n",
    "pokemon_df.iloc['?']=0\n",
    "\n",
    "#then replace all the r in the names with 'R' - use list comprehension \n",
    "pokemon_df['Name']='?'\n",
    "\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b7862",
   "metadata": {},
   "source": [
    "# 10. Example of cleaning data and making a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab08ad5",
   "metadata": {},
   "source": [
    "In this section we are going to clean up the Great Lakes Ice data we imported in the last lesson. I'll show you a workflow on how to get started building functions to help read in multiple files with the same formatting. Keep in mind this is a simple example to get you started and your data will require you to learn how to process your own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1334d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the data\n",
    "ice=pd.read_table(datadirectory+'gl_2019_2020_ice.csv')\n",
    "ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fd368",
   "metadata": {},
   "source": [
    "This table doesn't look good, I'll have to skip 5 rows when reading to actually get to my data. But for now let's grab the second row(python counting) since this row has the column names we will need. I'll do some string manipulation to ge the names in a useful format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_names=ice.iloc[2,].str.split(\" +\", n = 8, expand = True)\n",
    "ice_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12558d42",
   "metadata": {},
   "source": [
    "Now that I have a nice table I'll use the column names and the first row values to make a dictionary of names for my columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_names_dict=dict(zip(ice_names.keys(),ice_names.iloc[0,]))\n",
    "ice_names_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e4a55",
   "metadata": {},
   "source": [
    "Let's go back to the data and import again but skip the first 5 rows that don't have data, tell pandas we don't have a header since the formatting is bad. I also need to find the right delimiter since _csv didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33575f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean=pd.read_csv(datadirectory+'gl_2018_2019_ice.csv',skiprows=5,header=None,delimiter='\\t')\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5badbe",
   "metadata": {},
   "source": [
    "That didn't work. Let's do one more try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean=pd.read_csv(datadirectory+'gl_2018_2019_ice.csv',skiprows=5,header=None,delimiter=' ')\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0133846",
   "metadata": {},
   "source": [
    "Ok so there are multiple spaces as sepeartors (3 of them per column) so I will use a special paramter called delim_whitespace and hope it works. \n",
    "\n",
    "At this point I went to google to learn about delimiters. [pd.read_csv documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean=pd.read_csv(datadirectory+'gl_2018_2019_ice.csv',skiprows=5,header=None,delim_whitespace=True)\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5dbd00",
   "metadata": {},
   "source": [
    "YAY!!! Happy that worked.\n",
    "\n",
    "Let's change the column names with the dictionary we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean.rename(columns=ice_names_dict,inplace=True)\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659cf577",
   "metadata": {},
   "source": [
    "I don't like the long names, let's change them to initials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d52d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_initials={'Sup.':'SU','Mich.':'MI','Huron':'HU','Erie':'ER','Ont.':'ON'}\n",
    "\n",
    "ice_clean.rename(columns=lake_initials,inplace=True)\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51beab75",
   "metadata": {},
   "source": [
    "Let's drop the info for St. Claire lake and the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean.drop(['St.Clr','GL Total'],axis=1,inplace=True)\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17a1d0",
   "metadata": {},
   "source": [
    "At this point I am getting curious about which lake freezes first and the most. So I am going to make a quick line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_clean.plot(y=ice_clean.keys()[2:],kind='line',ylabel='ice_con%',xlabel='winter 2018-2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4e147",
   "metadata": {},
   "source": [
    "Looks like ER is the firts one to get over 50% ice - makes since that it freesez faster since it is the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c93ce",
   "metadata": {},
   "source": [
    "## HW problem 2 will allow you to practice importing data and getting it ready for a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a8eae",
   "metadata": {},
   "source": [
    "# 10.1 Automation - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69c5f0",
   "metadata": {},
   "source": [
    "Now, we did all of this for one file but the reality is that I need multiple years of this data. Let's make a function so I don't have to repeat these steps everytime I want the ice data. The following function will work with any year but I've only given you data from 2015-2019 so if you run other years it will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587367d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ice_data(year):\n",
    "    #read in data but only first 5 rows since we know we need to chage the reading parameters\n",
    "    #use f_format to change the values in the string \n",
    "    read_in_data=pd.read_table(datadirectory+f'gl_{year}_{year+1}_ice.csv',nrows=5)\n",
    "    \n",
    "    #get column names\n",
    "    ice_names=read_in_data.iloc[2].str.split(\" +\", n = 8, expand = True)\n",
    "    ice_names_dict=dict(zip(ice_names.keys(),ice_names.iloc[0,]))\n",
    "    \n",
    "    #make a clean table\n",
    "    ice_clean=pd.read_csv(datadirectory+f'gl_{year}_{year+1}_ice.csv',skiprows=5,header=None,delim_whitespace=True)\n",
    "    ice_clean.rename(columns=ice_names_dict,inplace=True)\n",
    "    lake_initials={'Sup.':'SU','Mich.':'MI','Huron':'HU','Erie':'ER','Ont.':'ON'}\n",
    "    ice_clean.rename(columns=lake_initials,inplace=True)\n",
    "    ice_clean.drop(['St.Clr','GL Total'],axis=1,inplace=True)\n",
    "    \n",
    "    #return the clean table\n",
    "    return ice_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we only have data from 2015-2019\n",
    "get_ice_data(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673e0c0",
   "metadata": {},
   "source": [
    "# 11. Combining tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22374d5f",
   "metadata": {},
   "source": [
    "## 11.1 Merge\n",
    "Merge allows you to combine tables that have a column with the same values. If teh column you are using as your key has the same name in all of your tables then you can use on=['name of column'] if not then you need to specify which column to use for each of your tables.\n",
    "\n",
    "\n",
    "Full function:\n",
    "\n",
    "\n",
    "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
    "\n",
    "\n",
    "[Merge documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745388d8",
   "metadata": {},
   "source": [
    "- ###  same name for key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the columns [year,day,su,mi,hu]\n",
    "ice_2015_16_MI_HU=get_ice_data(2015).iloc[:,[0,1,2,3,4]]\n",
    "display(ice_2015_16_MI_HU)\n",
    "\n",
    "#select only the columns [year,day,er,on]\n",
    "ice_2015_16_ON_ER=get_ice_data(2015).iloc[:,[0,1,5,6]]\n",
    "display(ice_2015_16_ON_ER)\n",
    "\n",
    "#merge the two frames to get the full table - use the columns they have in common - year and day\n",
    "Merge_ice=pd.merge(ice_2015_16_MI_HU,ice_2015_16_ON_ER,on=['Year','Day'])\n",
    "Merge_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4a90",
   "metadata": {},
   "source": [
    "- ###  different name for key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are making a subset here, same as before, but not let's change the name of year \n",
    "ice_2015_16_MI_HU=get_ice_data(2015).iloc[:,[0,1,3,4]].rename(columns={'Year':'_year'})\n",
    "\n",
    "#this is the same subset as before\n",
    "ice_2015_16_ON_ER=get_ice_data(2015).iloc[:,[0,1,5,6]]\n",
    "\n",
    "#now year is in both tables but it is written differently so we need to specify which columns we want to use as our reference\n",
    "Merge_ice=pd.merge(ice_2015_16_MI_HU,ice_2015_16_ON_ER,left_on=['_year','Day'],right_on=['Year','Day'])\n",
    "Merge_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdd6a8",
   "metadata": {},
   "source": [
    "The tables merged but we ended up with two columns for year because the names are different. We can drop the column we don't want later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b1083",
   "metadata": {},
   "source": [
    "- ###  Chain Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same tables as previous examples\n",
    "ice_2015_16_MI_HU=get_ice_data(2015).iloc[:,[0,1,3,4]]\n",
    "ice_2015_16_ON_ER=get_ice_data(2015).iloc[:,[0,1,2,5,6]]\n",
    "\n",
    "#we can use .merge to attach to the table on the left\n",
    "master=ice_2015_16_MI_HU.merge(ice_2015_16_ON_ER, on=['Day','Year'])\n",
    "master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef21b48",
   "metadata": {},
   "source": [
    "- ###  Merging with >2 tables - See appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829145c5",
   "metadata": {},
   "source": [
    "## 11.2 [Concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n",
    "Concatenate allows you to combine tables that don't have data in common.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retreive the ice data from 2015\n",
    "ice_2015_16=get_ice_data(2015)\n",
    "\n",
    "#creat a list for our dataframes - ice data and pokemon\n",
    "frames_hold=[ice_2015_16,pokemon_df]\n",
    "\n",
    "#use concat to combine the tables in our frames list\n",
    "concat_example=pd.concat(frames_hold,axis=0)\n",
    "concat_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985633e",
   "metadata": {},
   "source": [
    "More commonly we use to combine tables with similar data that is split across different tables.\n",
    "\n",
    "- ###  on rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ice data for different years\n",
    "ice_2015_16=get_ice_data(2015)\n",
    "ice_2016_17=get_ice_data(2016)\n",
    "ice_2017_18=get_ice_data(2017)\n",
    "\n",
    "#make a list of tables\n",
    "frames_rows=[ice_2015_16,ice_2016_17,ice_2017_18]\n",
    "\n",
    "#use concat to combine the tables, here with axis=0 we are telling concat to combine based on rows. \n",
    "#This works because all of our years have the same column names.\n",
    "Master_ice_concat_rows=pd.concat(frames_rows,axis=0)\n",
    "\n",
    "Master_ice_concat_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc1842",
   "metadata": {},
   "source": [
    "- ###  on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6df34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ice data for some lakes\n",
    "ice_2015_16_MI_HU=get_ice_data(2015).iloc[:,[0,1,3,4]]\n",
    "display(ice_2015_16_MI_HU)\n",
    "ice_2015_16_ON_ER=get_ice_data(2015).iloc[:,[5,6]]\n",
    "display(ice_2015_16_ON_ER)\n",
    "\n",
    "#list of tables\n",
    "frames_cols=[ice_2015_16_MI_HU,ice_2015_16_ON_ER]\n",
    "\n",
    "#combine tables in frames_cols, not we tell comcat that axis=1 because we want to combine the columns\n",
    "Master_ice_concat_cols=pd.concat(frames_cols,axis=1)\n",
    "\n",
    "Master_ice_concat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e55749",
   "metadata": {},
   "source": [
    "## 11.3 [Append](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.append.html)\n",
    "Append adds values to the end of a list. In the case of dataframes it adds to the end of the table. It works very similarly to concat except that with append you can start with an empty dataframe and concat needs an existing frame to add on to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ea1fe",
   "metadata": {},
   "source": [
    "- ###  with empty frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a172fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start an empty frame \n",
    "empty_frame=pd.DataFrame()\n",
    "display(empty_frame)\n",
    "\n",
    "#get some ice data\n",
    "Working_ice_df=get_ice_data(2015)\n",
    "\n",
    "#new table that is the result of adding ice data to the empty data \n",
    "combine_frames=empty_frame.append(Working_ice_df)\n",
    "combine_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9643a",
   "metadata": {},
   "source": [
    "- ###  with existing frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ice data\n",
    "Working_ice_df=get_ice_data(2015)\n",
    "#a different year of ice data\n",
    "new_ice=get_ice_data(2016)\n",
    "\n",
    "#use append to add 2016ice data to the 2015 ice data\n",
    "combine_years=Working_ice_df.append(new_ice)\n",
    "combine_years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450143bb",
   "metadata": {},
   "source": [
    "# 11. Skill check\n",
    "Combine these dataframes using the Merge method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e912c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df1=pd.DataFrame({'names':['Gohan','Naruto','Luffy'],'color':['blue','orange','red']})\n",
    "my_df2=pd.DataFrame({'names':['Gohan','Naruto','Luffy'],'power':[9000,8000,7000]})\n",
    "my_df3=pd.DataFrame({'power':[9000,8000,7000],'enemy':['Cell','Sasuke','Blackbeard']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841058f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can merge df1 and df2, and then add df3 to df1+df2 in multiple lines, or you can do all the merging in one line of code \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9a8d7",
   "metadata": {},
   "source": [
    "# 12. Change the layout of the dataframe - SKIP IN CLASS IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reference\n",
    "ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5ddf7",
   "metadata": {},
   "source": [
    "- ## 12.1 [Melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)\n",
    "\n",
    "Change the table form wide to long format.\n",
    "\n",
    "pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n",
    "\n",
    "There is also a command called [wide_to_long](https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html#pandas.wide_to_long), but I use melt more often.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.melt we must pass what variables we want as our id, these are the columns that will stay the same\n",
    "#value_vars are the columns we want to melt \n",
    "#then we need var_name the new name for the column that will hold the columns we indicated in value_vars\n",
    "#value_name is the name of the new_column that will hold all the values\n",
    "melt_ice_clean=pd.melt(ice_clean,id_vars=['Year','Day'],value_vars=['SU', 'MI','ON','HU','ER'],var_name='Lake', value_name='ice_concentration%')\n",
    "melt_ice_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043783b7",
   "metadata": {},
   "source": [
    "- ## 12.2 Pivot tables aka unmelt\n",
    "\n",
    "If you have a table in long format and you want wide we need to 'unmelt' it, to do this we use pivot tables.\n",
    "[Pivot documentation](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html)\n",
    "\n",
    "More on pivot tables in the Day10 lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to unmelt ot pivot we need to call an index, the columns we will use as a reference and will not change\n",
    "#then the columns is the column with the categories that will each become one column\n",
    "#the last argument is values that's the column that holds the values that will be moved to each column that gets created\n",
    "melt_ice_clean.pivot(index=['Year','Day'], columns='Lake', values='ice_concentration%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90547bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rest the index so Year and name become columns instead of the index\n",
    "melt_ice_clean.pivot(index=['Year','Day'], columns='Lake', values='ice_concentration%').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624ce83",
   "metadata": {},
   "source": [
    "# 13. Automation - Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88009e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_ice=pd.DataFrame()\n",
    "\n",
    "for i in range(2015,2019):\n",
    "    #this variable will hold the output of our function\n",
    "    ice_data=get_ice_data(i)\n",
    "    #here we append the output of our function to our master table\n",
    "    Master_ice=Master_ice.append(ice_data)\n",
    "\n",
    "#outside the for loop and last line to see our full table\n",
    "Master_ice    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c9fc4",
   "metadata": {},
   "source": [
    "# Quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8008858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's drop the time columns because we don't need them\n",
    "Master_ice=Master_ice.drop(columns=['Day','Year'],axis=1)\n",
    "Master_ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call a plot, and use subplots to get one subplot for each column, make pretty by adding label names \n",
    "Master_ice.plot(subplots=True,ylim=(0,99),xlabel='Day',ylabel='Temp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1e9ad",
   "metadata": {},
   "source": [
    "# Fill in table with loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e9a58",
   "metadata": {},
   "source": [
    "In this exmaple I'll show you how to populate a dataframe with a for loop, **yes** for this data there is much faster way to get this dataframe but I want to show you the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89eaa2",
   "metadata": {},
   "source": [
    "## [Regular expression operations (RE) documentation](https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Amanda','Katie','Maria']\n",
    "program=['Physics','Bio','Geo']\n",
    "field=['space','bugs','water']\n",
    "\n",
    "#dictionary with name and program \n",
    "name_program_dict=dict(zip(names,program))\n",
    "\n",
    "#new table with range of three and three column names too \n",
    "new_frame=pd.DataFrame(index=range(3),columns=['names','program','color','field'])\n",
    "display(new_frame)\n",
    "\n",
    "#Regular Expressions library\n",
    "import re\n",
    "\n",
    "#use eneumerate to get the index of the list inside enumerate \n",
    "#here k will be the index of i where i is the item in the list names\n",
    "for k,i in enumerate(names):\n",
    "    print('from eneumrate k is {}, this is the index of {} in the list names'.format(k,i))\n",
    "\n",
    "#to see the list\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79605610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use re to look for a specific string in a longer string and do something if the string is found \n",
    "for i in names:\n",
    "    if re.search('e',i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7989ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use iloc to put values in a specific spor\n",
    "new_frame2=new_frame.copy()\n",
    "new_frame2.iloc[0,0]='Amanda'\n",
    "new_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e93a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Amanda','Katie','Maria']\n",
    "program=['Physics','Bio','Geo']\n",
    "field=['space','bugs','water']\n",
    "\n",
    "#dictionary with name and program \n",
    "name_program_dict=dict(zip(names,program))\n",
    "\n",
    "#new table with range of three and three column names too \n",
    "new_frame=pd.DataFrame(index=range(3),columns=['names','program','color','field'])\n",
    "\n",
    "for k,i in enumerate(names):\n",
    "    #here k is the index value of names- so we can use the location to add a value there\n",
    "    #print(k,i)\n",
    "    \n",
    "    #select the row with enumerate and the column with a value\n",
    "    new_frame.iloc[k,0]=i\n",
    "    #the second column will have the dictionary value for a name\n",
    "    new_frame.iloc[k,1]=name_program_dict.get(i)\n",
    "    \n",
    "    #the third column will be populated by this statement \n",
    "    #if the name in names has r the person likes green, otherwise purple\n",
    "    if re.search('r',i):\n",
    "        j=f'{i} likes green'\n",
    "    else:\n",
    "        j=f'{i} likes purple'\n",
    "    \n",
    "    #this third column will take the value of j created in the previous lines\n",
    "    new_frame.iloc[k,2]=j  \n",
    "    \n",
    "    #the fourth colum will get populated by this statemnt\n",
    "    new_frame.iloc[k,3]=f'{i} studies {field[k]}' \n",
    "\n",
    "#remeber to call the table in the last line of the cell so we can see it   \n",
    "new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43688fc9",
   "metadata": {},
   "source": [
    "# 13. Skill Check\n",
    "Create a new table using the methods I showed above. The table should have 4 columns- one for cities you have visited (aim for 4, you can make them up), another for your favorite food in that city, a third for the person you were with, and a fourth with the number of letters in the food you had. I've given you pseudocode to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make your lists\n",
    "city=[]\n",
    "food=[]\n",
    "company=[]\n",
    "\n",
    "#dictionary with city and food\n",
    "name_food_dict=\n",
    "\n",
    "#new table with range of three and three column names too \n",
    "new_frame=pd.DataFrame(index=range(4),columns=['city','food','company','letters in food'])\n",
    "\n",
    "for k,i in enumerate(city):\n",
    "    #this line should add values to the 0 row in new_frame -city\n",
    "    \n",
    "    \n",
    "    #this line should add values to the 1 row in new_frame- food- you will need your dict \n",
    "    \n",
    "    \n",
    "    #this line should add values to the 2 row in new_frame- company\n",
    "      \n",
    "    \n",
    "    #this line should add values to the 3 row in new_frame- letters in food- you will need len and your dict\n",
    "    \n",
    "\n",
    "#remeber to call the table in the last line of the cell so we can see it   \n",
    "new_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf06c0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Today I showed you the following:\n",
    "\n",
    "1. Modify different parts of the dataframe\n",
    "2. Cleaning and making function \n",
    "3. Combining tables\n",
    "4. Automation (functions and for loops)\n",
    "\n",
    "I only showed you the basics to get you started, we will come back to these concepts in the following lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31c8b4",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac2e06",
   "metadata": {},
   "source": [
    "## merging many tables with common columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import this cool library that allows you to reduce dataframes to list and combine them\n",
    "from functools import reduce\n",
    "\n",
    "#make your tables- here each table holds 1 lake\n",
    "ice_2015_16_SU=get_ice_data(2015).iloc[:,[0,1,2]].copy()\n",
    "ice_2015_16_MI=get_ice_data(2015).iloc[:,[0,1,3]].copy()\n",
    "ice_2015_16_HU=get_ice_data(2015).iloc[:,[0,1,4]].copy()\n",
    "ice_2015_16_ER=get_ice_data(2015).iloc[:,[0,1,5]].copy()\n",
    "ice_2015_16_ON=get_ice_data(2015).iloc[:,[0,1,6]].copy()\n",
    "\n",
    "# create a list of the tables you want to combine \n",
    "my_dataframes=[ice_2015_16_SU, ice_2015_16_MI, ice_2015_16_HU, ice_2015_16_ER, ice_2015_16_ON]\n",
    "\n",
    "#initialiaze a variable that will hold the new combined dataframe\n",
    "#reduce(lambda df_left,df_right: pd.merge(df_left,df_right), on=[on what column to mege], the list of the columns to merge)\n",
    "combined_frame=reduce(lambda df_left,df_right: pd.merge(df_left, df_right, on=['Year','Day']), my_dataframes)\n",
    "combined_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9b7df",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755e4c6",
   "metadata": {},
   "source": [
    "1. Using the tools I've showed you so far - I challenge to create a plot of day vs temp for the cities that Katie may move to. Each city should have its own subplot. I have written steps for you below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cce925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the cities Katie could move to\n",
    "cities=['juno','austin','seattle','philadelphia']\n",
    "\n",
    "#a function that opens the city file and return the column with average, the only argument it takes in is the name of the city \n",
    "def open_june_average(city):\n",
    "    #you need one line of code to open the file- use the correct command to open a txt\n",
    "    #notice all the file names end with june21.txt and you only have to change the city name, use f'{}' to help open the files\n",
    "    #also note that these files do not have a header\n",
    "    #there are three columns, and the second column or index 1 is the one with the average\n",
    "    #the columns do not have name so after selecting to yse the columns with average give it a name\n",
    "    #the name should be dynamic- so city_mean where city changes based on the city you give the function \n",
    "    city_file=?\n",
    "    #return the file \n",
    "    return city_file\n",
    "\n",
    "#create a new list that will hold the tables we make for each city \n",
    "city_info=?\n",
    "\n",
    "#use a for loop to run open_june_average for each city, the append the table to the city_info list using append \n",
    "for i in cities:\n",
    "    #run run open_june_average and save to some variable\n",
    "    \n",
    "    #then append the data to city_info\n",
    "\n",
    "\n",
    "#combine all the tables in the city_info list, we are combining by columns so remember to use the correct axis \n",
    "full_table=pd.concat(city_info,axis=?)\n",
    "\n",
    "#make a plot from the table - I wrote all the commands for you already - but you make the plot pretty \n",
    "#the xlabel should be day and y label Temp, change the limits so all the y axis are the same \n",
    "full_table.plot(subplots=True,ylim=(50,90))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a033c",
   "metadata": {},
   "source": [
    "2. In the data folder,  I've given you two files with whole lake average daily surface water temp temperature, one from 2010-2015 and the other from 2016-2020. The files have data for all the lakes. Crate a function that allows you to open the files, combine them to have 2010-2020 in one table, and return the subset of the data that belongs to a lake of interest. You'll notice the column names are in lower case, change the names so that the first letter is uppercase. Your function should take one argument - the initials of the lake we want, and return a table with data from 2010-2020 for that lake. We will do some math on this temperature data in the next lesson.\n",
    "   **Yes you could do this manually in excel but practice your coding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a815a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lake_wanted(lake):\n",
    "    #read in data for 2010-2015\n",
    "    temp_data_2010_2015=?\n",
    "    #read in data for 2016-2020\n",
    "    temp_data_2016_2020=?\n",
    "    #make a list of your data\n",
    "    frames=?\n",
    "    #combine the tables in your data list - concat, and remmber the index\n",
    "    full_temp=?\n",
    "    #create a table that only holds the lake that we pass to the function - use loc\n",
    "    lake_wanted=?\n",
    "    #rename the columns so they start with an upper case letter , remember inplace\n",
    "    lake_wanted.rename(?)\n",
    "    #return your lake wanted\n",
    "    return lake_wanted\n",
    "\n",
    "get_lake_wanted('MI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
